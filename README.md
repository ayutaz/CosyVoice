[![SVG Banners](https://svg-banners.vercel.app/api?type=origin&text1=CosyVoice2ğŸ¤ &text2=Next-Gen%20Streaming%20TTS%20ğŸ’–%20Qwen2&width=800&height=210)](https://github.com/Akshay090/svg-banners)

## ğŸ‘‰ğŸ» CosyVoice 2.0 ğŸ‘ˆğŸ»

**æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ - CosyVoice 2.0 (0.5B)**

[Demos](https://funaudiollm.github.io/cosyvoice2/) | [Paper](https://arxiv.org/abs/2412.10117) | [Modelscope](https://www.modelscope.cn/studios/iic/CosyVoice2-0.5B) | [HuggingFace](https://huggingface.co/spaces/FunAudioLLM/CosyVoice2-0.5B)

## HighlightğŸ”¥

**CosyVoice 2.0** ã¯ã€ã‚ˆã‚Šæ­£ç¢ºã§ã€ã‚ˆã‚Šå®‰å®šã—ãŸã€ã‚ˆã‚Šé«˜é€Ÿã§ã€ã‚ˆã‚Šå„ªã‚ŒãŸéŸ³å£°ç”Ÿæˆæ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚

### å¤šè¨€èªå¯¾å¿œ
- **å¯¾å¿œè¨€èª**: ä¸­å›½èªã€è‹±èªã€æ—¥æœ¬èªã€éŸ“å›½èªã€ä¸­å›½èªæ–¹è¨€ï¼ˆåºƒæ±èªã€å››å·èªã€ä¸Šæµ·èªã€å¤©æ´¥èªã€æ­¦æ¼¢èªãªã©ï¼‰
- **ã‚¯ãƒ­ã‚¹ãƒªãƒ³ã‚¬ãƒ« & ã‚³ãƒ¼ãƒ‰ã‚¹ã‚¤ãƒƒãƒãƒ³ã‚°**: ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆéŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚‹è¨€èªæ¨ªæ–­ãƒ»ã‚³ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆã‚·ãƒŠãƒªã‚ªã‚’ã‚µãƒãƒ¼ãƒˆ

### è¶…ä½é…å»¶
- **åŒæ–¹å‘ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œ**: CosyVoice 2.0ã¯ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã¨ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã®ãƒ¢ãƒ‡ãƒªãƒ³ã‚°æŠ€è¡“ã‚’çµ±åˆ
- **é«˜é€ŸFirst Packetåˆæˆ**: é«˜å“è³ªãªéŸ³å£°å‡ºåŠ›ã‚’ç¶­æŒã—ãªãŒã‚‰ã€150msä»¥ä¸‹ã®é…å»¶ã‚’å®Ÿç¾

### é«˜ç²¾åº¦
- **ç™ºéŸ³ç²¾åº¦å‘ä¸Š**: CosyVoice 1.0ã¨æ¯”è¼ƒã—ã¦ç™ºéŸ³ã‚¨ãƒ©ãƒ¼ã‚’30%ã€œ50%å‰Šæ¸›
- **ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é”æˆ**: Seed-TTSè©•ä¾¡ã‚»ãƒƒãƒˆã®ãƒãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§æœ€ä½æ–‡å­—ã‚¨ãƒ©ãƒ¼ç‡ã‚’é”æˆ

### å¼·åŠ›ãªå®‰å®šæ€§
- **éŸ³è‰²ã®ä¸€è²«æ€§**: ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆãŠã‚ˆã³ã‚¯ãƒ­ã‚¹ãƒ©ãƒ³ã‚²ãƒ¼ã‚¸éŸ³å£°åˆæˆã§ç¢ºå®ŸãªéŸ³å£°ä¸€è²«æ€§ã‚’ä¿è¨¼
- **ã‚¯ãƒ­ã‚¹ãƒ©ãƒ³ã‚²ãƒ¼ã‚¸åˆæˆ**: ãƒãƒ¼ã‚¸ãƒ§ãƒ³1.0ã¨æ¯”è¼ƒã—ã¦å¤§å¹…ã«æ”¹å–„

### è‡ªç„¶ãªä½“é¨“
- **éŸ»å¾‹ã¨éŸ³è³ªã®å‘ä¸Š**: åˆæˆéŸ³å£°ã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆãŒæ”¹å–„ã•ã‚Œã€MOSè©•ä¾¡ã‚¹ã‚³ã‚¢ãŒ5.4ã‹ã‚‰5.53ã«å‘ä¸Š
- **æ„Ÿæƒ…ã¨æ–¹è¨€ã®æŸ”è»Ÿæ€§**: ã‚ˆã‚Šãã‚ç´°ã‹ã„æ„Ÿæƒ…åˆ¶å¾¡ã¨ã‚¢ã‚¯ã‚»ãƒ³ãƒˆèª¿æ•´ã‚’ã‚µãƒãƒ¼ãƒˆ

## ä¸»è¦æ©Ÿèƒ½

### Qwen2ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
- äº‹å‰å­¦ç¿’æ¸ˆã¿Qwen2ForCausalLMã‚’æ´»ç”¨
- 500Mãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
- Bidirectional Streaming: ãƒ†ã‚­ã‚¹ãƒˆã¨éŸ³å£°ã‚’5:15ã®æ¯”ç‡ã§æ··åˆ

### ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ€§èƒ½
- First Chunk Latency: 150msä»¥ä¸‹
- å› æœçš„Flow Matchingï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œï¼‰
- ãƒãƒ£ãƒ³ã‚¯å˜ä½ã®å‡¦ç†ã¨KVã‚­ãƒ£ãƒƒã‚·ãƒ¥

### æœ€é©åŒ–ã‚ªãƒ—ã‚·ãƒ§ãƒ³
- **vLLMçµ±åˆ**: 4å€é«˜é€ŸåŒ–
- **TensorRT-LLM**: 2.3å€é«˜é€ŸåŒ–ï¼ˆTritonä½¿ç”¨ï¼‰
- **JIT/ONNX**: æ¨è«–æœ€é©åŒ–

### å¼·åŒ–å­¦ç¿’ï¼ˆGRPOï¼‰
- WERãƒ™ãƒ¼ã‚¹ã®Rewardé–¢æ•°
- ç™ºéŸ³ç²¾åº¦ã¨MOSè©•ä¾¡ã®å‘ä¸Š

## Install

### Clone and install

```sh
git clone https://github.com/FunAudioLLM/CosyVoice.git
cd CosyVoice
```

### ç’°å¢ƒã®æ§‹ç¯‰

```sh
# uvã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã®å ´åˆï¼‰
curl -LsSf https://astral.sh/uv/install.sh | sh

# Python 3.10ä»®æƒ³ç’°å¢ƒã®ä½œæˆ
uv venv --python 3.10 .venv

# ä»®æƒ³ç’°å¢ƒã®æœ‰åŠ¹åŒ–
source .venv/bin/activate  # Linux/macOS
# ã¾ãŸã¯
.venv\Scripts\activate  # Windows

# ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
uv pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com

# Soxäº’æ›æ€§å•é¡ŒãŒã‚ã‚‹å ´åˆ
# Ubuntu:
sudo apt-get install sox libsox-dev
# CentOS:
sudo yum install sox sox-devel
```

### ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

CosyVoice2-0.5Bãƒ¢ãƒ‡ãƒ«ã¨ttsfrdãƒªã‚½ãƒ¼ã‚¹ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚

```python
# SDKçµŒç”±ã®ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
from modelscope import snapshot_download
snapshot_download('iic/CosyVoice2-0.5B', local_dir='pretrained_models/CosyVoice2-0.5B')
snapshot_download('iic/CosyVoice-ttsfrd', local_dir='pretrained_models/CosyVoice-ttsfrd')
```

```sh
# GitçµŒç”±ã®ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆgit lfsãŒå¿…è¦ï¼‰
mkdir -p pretrained_models
git clone https://www.modelscope.cn/iic/CosyVoice2-0.5B.git pretrained_models/CosyVoice2-0.5B
git clone https://www.modelscope.cn/iic/CosyVoice-ttsfrd.git pretrained_models/CosyVoice-ttsfrd
```

ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã€`ttsfrd`ãƒªã‚½ãƒ¼ã‚¹ã‚’è§£å‡ã—ã€`ttsfrd`ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã“ã¨ã§ã€ãƒ†ã‚­ã‚¹ãƒˆæ­£è¦åŒ–ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå‘ä¸Šã—ã¾ã™ã€‚

ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã¯å¿…é ˆã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚`ttsfrd`ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ãªã„å ´åˆã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§wetextã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

```sh
cd pretrained_models/CosyVoice-ttsfrd/
unzip resource.zip -d .
pip install ttsfrd_dependency-0.1-py3-none-any.whl
pip install ttsfrd-0.4.2-cp310-cp310-linux_x86_64.whl
```

## Basic Usage

CosyVoice2-0.5Bã®ä½¿ç”¨ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚

```python
import sys
sys.path.append('third_party/Matcha-TTS')
from cosyvoice.cli.cosyvoice import CosyVoice2
from cosyvoice.utils.file_utils import load_wav
import torchaudio
```

### CosyVoice2ã®åŸºæœ¬çš„ãªä½¿ç”¨æ³•

```python
cosyvoice = CosyVoice2('pretrained_models/CosyVoice2-0.5B', load_jit=False, load_trt=False, load_vllm=False, fp16=False)

# NOTE: https://funaudiollm.github.io/cosyvoice2 ã®çµæœã‚’å†ç¾ã™ã‚‹å ´åˆã¯ã€æ¨è«–æ™‚ã« text_frontend=False ã‚’è¿½åŠ ã—ã¦ãã ã•ã„
# ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆä½¿ç”¨æ³•
prompt_speech_16k = load_wav('./asset/zero_shot_prompt.wav', 16000)
for i, j in enumerate(cosyvoice.inference_zero_shot('ååˆ°å¥½å‹ä»è¿œæ–¹å¯„æ¥çš„ç”Ÿæ—¥ç¤¼ç‰©ï¼Œé‚£ä»½æ„å¤–çš„æƒŠå–œä¸æ·±æ·±çš„ç¥ç¦è®©æˆ‘å¿ƒä¸­å……æ»¡äº†ç”œèœœçš„å¿«ä¹ï¼Œç¬‘å®¹å¦‚èŠ±å„¿èˆ¬ç»½æ”¾ã€‚', 'å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚', prompt_speech_16k, stream=False)):
    torchaudio.save('zero_shot_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)

# ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆè©±è€…ã‚’ä¿å­˜ã—ã¦å¾Œã§ä½¿ç”¨
assert cosyvoice.add_zero_shot_spk('å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚', prompt_speech_16k, 'my_zero_shot_spk') is True
for i, j in enumerate(cosyvoice.inference_zero_shot('ååˆ°å¥½å‹ä»è¿œæ–¹å¯„æ¥çš„ç”Ÿæ—¥ç¤¼ç‰©ï¼Œé‚£ä»½æ„å¤–çš„æƒŠå–œä¸æ·±æ·±çš„ç¥ç¦è®©æˆ‘å¿ƒä¸­å……æ»¡äº†ç”œèœœçš„å¿«ä¹ï¼Œç¬‘å®¹å¦‚èŠ±å„¿èˆ¬ç»½æ”¾ã€‚', '', '', zero_shot_spk_id='my_zero_shot_spk', stream=False)):
    torchaudio.save('zero_shot_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)
cosyvoice.save_spkinfo()

# ãã‚ç´°ã‹ã„åˆ¶å¾¡ï¼ˆã‚µãƒãƒ¼ãƒˆã•ã‚Œã‚‹åˆ¶å¾¡ã¯ cosyvoice/tokenizer/tokenizer.py#L248 ã‚’å‚ç…§ï¼‰
for i, j in enumerate(cosyvoice.inference_cross_lingual('åœ¨ä»–è®²è¿°é‚£ä¸ªè’è¯æ•…äº‹çš„è¿‡ç¨‹ä¸­ï¼Œä»–çªç„¶[laughter]åœä¸‹æ¥ï¼Œå› ä¸ºä»–è‡ªå·±ä¹Ÿè¢«é€—ç¬‘äº†[laughter]ã€‚', prompt_speech_16k, stream=False)):
    torchaudio.save('fine_grained_control_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)

# instructä½¿ç”¨æ³•
for i, j in enumerate(cosyvoice.inference_instruct2('ååˆ°å¥½å‹ä»è¿œæ–¹å¯„æ¥çš„ç”Ÿæ—¥ç¤¼ç‰©ï¼Œé‚£ä»½æ„å¤–çš„æƒŠå–œä¸æ·±æ·±çš„ç¥ç¦è®©æˆ‘å¿ƒä¸­å……æ»¡äº†ç”œèœœçš„å¿«ä¹ï¼Œç¬‘å®¹å¦‚èŠ±å„¿èˆ¬ç»½æ”¾ã€‚', 'ç”¨å››å·è¯è¯´è¿™å¥è¯', prompt_speech_16k, stream=False)):
    torchaudio.save('instruct_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)

# ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ä½¿ç”¨æ³•ã€ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’å…¥åŠ›ã¨ã—ã¦ä½¿ç”¨ã§ãã¾ã™ã€‚ã“ã‚Œã¯ãƒ†ã‚­ã‚¹ãƒˆLLMãƒ¢ãƒ‡ãƒ«ã‚’å…¥åŠ›ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹å ´åˆã«ä¾¿åˆ©ã§ã™
# NOTE: LLMã¯ä»»æ„ã®æ–‡ã®é•·ã•ã‚’å‡¦ç†ã§ããªã„ãŸã‚ã€åŸºæœ¬çš„ãªæ–‡ã®åˆ†å‰²ãƒ­ã‚¸ãƒƒã‚¯ãŒå¿…è¦ã§ã™
def text_generator():
    yield 'ååˆ°å¥½å‹ä»è¿œæ–¹å¯„æ¥çš„ç”Ÿæ—¥ç¤¼ç‰©ï¼Œ'
    yield 'é‚£ä»½æ„å¤–çš„æƒŠå–œä¸æ·±æ·±çš„ç¥ç¦'
    yield 'è®©æˆ‘å¿ƒä¸­å……æ»¡äº†ç”œèœœçš„å¿«ä¹ï¼Œ'
    yield 'ç¬‘å®¹å¦‚èŠ±å„¿èˆ¬ç»½æ”¾ã€‚'
for i, j in enumerate(cosyvoice.inference_zero_shot(text_generator(), 'å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚', prompt_speech_16k, stream=False)):
    torchaudio.save('zero_shot_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)
```

### CosyVoice2ã®vLLMä½¿ç”¨æ³•

vLLMã‚’æ¨è«–ã«ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€`vllm==v0.9.0`ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚å¤ã„vLLMãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯CosyVoice2æ¨è«–ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã›ã‚“ã€‚

`vllm==v0.9.0`ã«ã¯å¤šãã®ç‰¹å®šã®è¦ä»¶ãŒã‚ã‚Šã¾ã™ï¼ˆä¾‹: `torch==2.7.0`ï¼‰ã€‚ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãŒvLLMã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ãªã„å ´åˆã«å¤ã„ç’°å¢ƒãŒç ´æã—ãªã„ã‚ˆã†ã«ã€æ–°ã—ã„ç’°å¢ƒã‚’ä½œæˆã§ãã¾ã™ã€‚

```sh
# vLLMç”¨ã®åˆ¥ä»®æƒ³ç’°å¢ƒä½œæˆ
uv venv --python 3.10 .venv_vllm
source .venv_vllm/bin/activate  # Linux/macOS

# æ¨™æº–ã®ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
uv pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com

# vLLMé–¢é€£ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
uv pip install vllm==v0.9.0 transformers==4.51.3 -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com

# vLLMæ¨è«–ã®å®Ÿè¡Œ
python vllm_example.py
```

### Webãƒ‡ãƒ¢ã®èµ·å‹•

CosyVoice2ã‚’ç´ æ—©ãä½“é¨“ã™ã‚‹ã«ã¯ã€Webãƒ‡ãƒ¢ãƒšãƒ¼ã‚¸ã‚’ä½¿ç”¨ã§ãã¾ã™ã€‚

è©³ç´°ã¯ãƒ‡ãƒ¢Webã‚µã‚¤ãƒˆã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

```python
# CosyVoice2-0.5Bã‚’ä½¿ç”¨
python3 webui.py --port 50000 --model_dir pretrained_models/CosyVoice2-0.5B
```

### é«˜åº¦ãªä½¿ç”¨æ³•

ä¸Šç´šãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘ã«ã€`examples/libritts/cosyvoice2/run.sh`ã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŠã‚ˆã³æ¨è«–ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚

### ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆç”¨ã®ãƒ“ãƒ«ãƒ‰

ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã€ã‚µãƒ¼ãƒ“ã‚¹ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆãŒå¿…è¦ãªå ´åˆã¯ã€ä»¥ä¸‹ã®æ‰‹é †ã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚

#### FastAPI / gRPC ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ

```sh
cd runtime/python
docker build -t cosyvoice:v2.0 .

# gRPCä½¿ç”¨æ³•
docker run -d --runtime=nvidia -p 50000:50000 cosyvoice:v2.0 /bin/bash -c "cd /opt/CosyVoice/CosyVoice/runtime/python/grpc && python3 server.py --port 50000 --max_conc 4 --model_dir pretrained_models/CosyVoice2-0.5B && sleep infinity"
cd grpc && python3 client.py --port 50000 --mode zero_shot

# FastAPIä½¿ç”¨æ³•
docker run -d --runtime=nvidia -p 50000:50000 cosyvoice:v2.0 /bin/bash -c "cd /opt/CosyVoice/CosyVoice/runtime/python/fastapi && python3 server.py --port 50000 --model_dir pretrained_models/CosyVoice2-0.5B && sleep infinity"
cd fastapi && python3 client.py --port 50000 --mode zero_shot
```

#### Nvidia TensorRT-LLMã‚’ä½¿ç”¨ã—ãŸãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ

TensorRT-LLMã‚’ä½¿ç”¨ã—ã¦cosyvoice2ã®LLMã‚’åŠ é€Ÿã™ã‚‹ã¨ã€HuggingFace transformerså®Ÿè£…ã¨æ¯”è¼ƒã—ã¦4å€ã®é«˜é€ŸåŒ–ãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚

ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ:

```sh
cd runtime/triton_trtllm
docker compose up -d
```

è©³ç´°ã«ã¤ã„ã¦ã¯ã€[ã“ã¡ã‚‰](https://github.com/FunAudioLLM/CosyVoice/tree/main/runtime/triton_trtllm)ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚

## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### ã‚³ã‚¢ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

CosyVoice2ã¯3ã¤ã®ä¸»è¦ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™:

1. **LLM (Qwen2LM)**: ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰é›¢æ•£éŸ³å£°ãƒˆãƒ¼ã‚¯ãƒ³ã¸
   - Qwen2ForCausalLMãƒ™ãƒ¼ã‚¹
   - Bidirectional Streaming (5:15æ··åˆ)
   - éŸ³å£°ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 6,561

2. **Flow (CausalMaskedDiffWithXvec)**: éŸ³å£°ãƒˆãƒ¼ã‚¯ãƒ³ã‹ã‚‰ãƒ¡ãƒ«ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã¸
   - å› æœçš„Flow Matching
   - UpsampleConformerEncoder (2å€ã‚¢ãƒƒãƒ—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°)
   - static_chunk_size=25ã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œ

3. **HiFiGAN (HiFTGenerator)**: ãƒ¡ãƒ«ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã‹ã‚‰éŸ³å£°æ³¢å½¢ã¸
   - F0äºˆæ¸¬ + NSF
   - ã‚¢ãƒƒãƒ—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°: [8, 5, 3] â†’ 120å€
   - ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ: 24000 Hz

### ä¸»è¦ãªç‰¹å¾´

- **ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ**: 24000 Hz
- **ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆ**: 25 Hz
- **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°**: 500M
- **MOSè©•ä¾¡**: 5.53
- **First Chunk Latency**: 150msä»¥ä¸‹

## ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°

### ãƒ‡ãƒ¼ã‚¿æº–å‚™

```sh
cd examples/libritts/cosyvoice2

# Stage -1~3: ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€å‰å‡¦ç†ã€Parquetå¤‰æ›
bash run.sh
```

### ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°

```bash
# 3ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’é †ç•ªã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°: llm â†’ flow â†’ hifigan
export CUDA_VISIBLE_DEVICES="0,1,2,3"
for model in llm flow hifigan; do
    torchrun --nproc_per_node=4 \
      cosyvoice/bin/train.py \
      --train_engine torch_ddp \
      --config conf/cosyvoice2.yaml \
      --train_data data/train.data.list \
      --cv_data data/dev.data.list \
      --model $model \
      --checkpoint pretrained_models/CosyVoice2-0.5B/$model.pt \
      --model_dir exp/cosyvoice2/$model \
      --tensorboard_dir tensorboard/cosyvoice2/$model
done
```

### GRPOãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆå¼·åŒ–å­¦ç¿’ï¼‰

```sh
cd examples/grpo/cosyvoice2

# HuggingFaceå½¢å¼ã¸ã®å¤‰æ› â†’ GRPOè¨“ç·´ â†’ CosyVoiceå½¢å¼ã¸å¤‰æ›
bash run.sh
```

## ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæ€§èƒ½

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒï¼ˆL20 GPUï¼‰

| ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæ–¹æ³• | RTF (batch=8) | First Chunk Latency | ç›¸å¯¾é€Ÿåº¦ |
|-------------------|---------------|---------------------|----------|
| HuggingFaceå®Ÿè£… | 0.0947 | - | 1.0x |
| TensorRT-LLM | 0.0418 | 189ms | 2.3x |
| vLLMçµ±åˆ | ã•ã‚‰ã«é«˜é€Ÿ | - | 4.0x |

### ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæ–¹æ³•ã®é¸æŠ

| æ–¹æ³• | ç”¨é€” | ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· | ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ | å®Ÿè£…é›£æ˜“åº¦ |
|------|------|------------|--------------|------------|
| FastAPI | ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ”ãƒ³ã‚°ã€å°è¦æ¨¡ | ä¸­ | ä¸­ | ä½ |
| gRPC | æœ¬ç•ªç’°å¢ƒã€ä¸­è¦æ¨¡ | ä½ | é«˜ | ä¸­ |
| Triton+TensorRT-LLM | æœ¬ç•ªç’°å¢ƒã€å¤§è¦æ¨¡ã€æœ€é«˜æ€§èƒ½ | æœ€ä½ | æœ€é«˜ | é«˜ |

## æŠ€è¡“ä»•æ§˜

### ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶

**æœ€å°è¦ä»¶:**
- GPU: NVIDIA GPUï¼ˆ6GB VRAMä»¥ä¸Šï¼‰
- RAM: 16GB
- ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸: 10GBä»¥ä¸Š

**æ¨å¥¨è¦ä»¶:**
- GPU: NVIDIA GPUï¼ˆ12GB VRAMä»¥ä¸Šã€A100/L20æ¨å¥¨ï¼‰
- RAM: 32GBä»¥ä¸Š
- ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸: 50GBä»¥ä¸Š

**ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¦ä»¶:**
- GPU: è¤‡æ•°ã®NVIDIA GPUï¼ˆå„16GB VRAMä»¥ä¸Šï¼‰
- RAM: 64GBä»¥ä¸Š
- ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸: 500GBä»¥ä¸Š

### ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢è¦ä»¶

- **Python**: 3.10
- **PyTorch**: 2.3.1ï¼ˆæ¨™æº–ï¼‰ã€2.7.0ï¼ˆvLLMä½¿ç”¨æ™‚ï¼‰
- **CUDA**: 12.1
- **transformers**: 4.51.3
- **vllm**: v0.9.0ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

## Discussion & Communication

[GitHub Issues](https://github.com/FunAudioLLM/CosyVoice/issues)ã§ç›´æ¥ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ã§ãã¾ã™ã€‚

å…¬å¼DingDingãƒãƒ£ãƒƒãƒˆã‚°ãƒ«ãƒ¼ãƒ—ã«å‚åŠ ã™ã‚‹ã«ã¯ã€QRã‚³ãƒ¼ãƒ‰ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦ãã ã•ã„ã€‚

<img src="./asset/dingding.png" width="250px">

## Acknowledge

1. [FunASR](https://github.com/modelscope/FunASR)ã‹ã‚‰å¤šãã®ã‚³ãƒ¼ãƒ‰ã‚’å€Ÿç”¨ã—ã¾ã—ãŸã€‚
2. [FunCodec](https://github.com/modelscope/FunCodec)ã‹ã‚‰å¤šãã®ã‚³ãƒ¼ãƒ‰ã‚’å€Ÿç”¨ã—ã¾ã—ãŸã€‚
3. [Matcha-TTS](https://github.com/shivammehta25/Matcha-TTS)ã‹ã‚‰å¤šãã®ã‚³ãƒ¼ãƒ‰ã‚’å€Ÿç”¨ã—ã¾ã—ãŸã€‚
4. [AcademiCodec](https://github.com/yangdongchao/AcademiCodec)ã‹ã‚‰å¤šãã®ã‚³ãƒ¼ãƒ‰ã‚’å€Ÿç”¨ã—ã¾ã—ãŸã€‚
5. [WeNet](https://github.com/wenet-e2e/wenet)ã‹ã‚‰å¤šãã®ã‚³ãƒ¼ãƒ‰ã‚’å€Ÿç”¨ã—ã¾ã—ãŸã€‚

## Citations

```bibtex
@article{du2024cosyvoice2,
  title={Cosyvoice 2: Scalable streaming speech synthesis with large language models},
  author={Du, Zhihao and Wang, Yuxuan and Chen, Qian and Shi, Xian and Lv, Xiang and Zhao, Tianyu and Gao, Zhifu and Yang, Yexin and Gao, Changfeng and Wang, Hui and others},
  journal={arXiv preprint arXiv:2412.10117},
  year={2024}
}

@article{du2025cosyvoice3,
  title={CosyVoice 3: Towards In-the-wild Speech Generation via Scaling-up and Post-training},
  author={Du, Zhihao and Gao, Changfeng and Wang, Yuxuan and Yu, Fan and Zhao, Tianyu and Wang, Hao and Lv, Xiang and Wang, Hui and Shi, Xian and An, Keyu and others},
  journal={arXiv preprint arXiv:2505.17589},
  year={2025}
}

@inproceedings{lyu2025build,
  title={Build LLM-Based Zero-Shot Streaming TTS System with Cosyvoice},
  author={Lyu, Xiang and Wang, Yuxuan and Zhao, Tianyu and Wang, Hao and Liu, Huadai and Du, Zhihao},
  booktitle={ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--2},
  year={2025},
  organization={IEEE}
}
```

## Disclaimer

ä¸Šè¨˜ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å­¦è¡“ç›®çš„ã®ã¿ã®ãŸã‚ã«æä¾›ã•ã‚Œã¦ãŠã‚Šã€æŠ€è¡“çš„ãªèƒ½åŠ›ã‚’ç¤ºã™ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚ä¸€éƒ¨ã®ä¾‹ã¯ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆã‹ã‚‰å–å¾—ã—ãŸã‚‚ã®ã§ã™ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒã‚ãªãŸã®æ¨©åˆ©ã‚’ä¾µå®³ã—ã¦ã„ã‚‹å ´åˆã¯ã€å‰Šé™¤ã‚’è¦æ±‚ã™ã‚‹ãŸã‚ã«ã”é€£çµ¡ãã ã•ã„ã€‚
