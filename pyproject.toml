[project]
name = "cosyvoice"
version = "0.1.0"
description = "CosyVoice - Text-to-Speech with Large Language Model"
readme = "README.md"
requires-python = ">=3.10,<3.11"
dependencies = [
    # Core ML frameworks (install first)
    "torch==2.3.1",
    "torchaudio==2.3.1",
    # Audio processing
    "librosa==0.10.2",
    "soundfile==0.12.1",
    "pyworld==0.3.4",
    # Model & inference
    "transformers==4.51.3",
    "diffusers==0.29.0",
    "openai-whisper==20231117",
    "modelscope==1.20.0",
    "onnx==1.16.0",
    # Transformer architectures
    "conformer==0.3.2",
    "x-transformers==2.11.24",
    # Configuration
    "hydra-core==1.3.2",
    "hyperpyyaml==1.2.2",
    "omegaconf==2.3.0",
    # Web & API
    "fastapi==0.115.6",
    "fastapi-cli==0.0.4",
    "uvicorn==0.30.0",
    "gradio==5.4.0",
    "grpcio==1.57.0",
    "grpcio-tools==1.57.0",
    # Data processing
    "numpy==1.26.4",
    "pyarrow==18.1.0",
    "networkx==3.1",
    # Text processing
    "inflect==7.3.1",
    "wetext==0.0.4",
    # Utilities
    "gdown==5.1.0",
    "wget==3.2",
    "rich==13.7.1",
    "matplotlib==3.7.5",
    "pydantic==2.7.0",
    "protobuf==4.25",
    # Training
    "lightning==2.2.4",
    "tensorboard==2.14.0",
    # ONNX Runtime (CPU/DirectML for Windows/Mac)
    "onnxruntime==1.18.0",
    "ruamel-yaml<0.18",
    "pyopenjtalk-plus>=0.4.1.post7",
    "optimum>=2.1.0",
    "onnxconverter-common>=1.16.0",
    "openai>=2.15.0",
    "huggingface-hub>=0.36.0",
]

# Note: For Linux training with GPU acceleration, manually install:
# uv add deepspeed tensorrt-cu12 tensorrt-cu12-bindings tensorrt-cu12-libs onnxruntime-gpu

[tool.uv]
index-strategy = "unsafe-best-match"
extra-index-url = [
    "https://download.pytorch.org/whl/cu121",
]
